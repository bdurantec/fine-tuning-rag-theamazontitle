{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "f_RXsRDMkBAv"
      ],
      "authorship_tag": "ABX9TyOjTHQvnbnUKOWjnm/zD4v6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20968348f74140429922b6088608995b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9429c9c5046c43b78fff1ea0a62a9381",
              "IPY_MODEL_b18b4ba9a4dc4001931b597bafd6a23c",
              "IPY_MODEL_2f0e69c760674f8c96e479e2adffd2ee"
            ],
            "layout": "IPY_MODEL_cf2b700ee28b4526836f64099935753f"
          }
        },
        "9429c9c5046c43b78fff1ea0a62a9381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ba2a7c5b7d45ae94be3acae56f504e",
            "placeholder": "​",
            "style": "IPY_MODEL_6015fedff32d484d91a0a68607aca932",
            "value": "Map: 100%"
          }
        },
        "b18b4ba9a4dc4001931b597bafd6a23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fe11443601c48fd9e8415ad155015dc",
            "max": 2494,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6243ca6b4b37486284229f5874cb37a9",
            "value": 2494
          }
        },
        "2f0e69c760674f8c96e479e2adffd2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f5bb9e6044431a9b5ecc1e3dacc511",
            "placeholder": "​",
            "style": "IPY_MODEL_f985d323bc4442c19c0bd8bf7f3b1702",
            "value": " 2494/2494 [00:02&lt;00:00, 1269.10 examples/s]"
          }
        },
        "cf2b700ee28b4526836f64099935753f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ba2a7c5b7d45ae94be3acae56f504e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6015fedff32d484d91a0a68607aca932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fe11443601c48fd9e8415ad155015dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6243ca6b4b37486284229f5874cb37a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9f5bb9e6044431a9b5ecc1e3dacc511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f985d323bc4442c19c0bd8bf7f3b1702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio\n",
        "\n",
        "Executar o fine-tuning de um foudation model (Llama, Bert, Minstrel, etc), utilizando o dataset \"TheAmazonTtiles-1.3MM\". <br>\n",
        "O modelo treinado deverá:\n",
        "- Receber perguntas com um contexto obtido por meio de uma integração RAG (Retrieve-and-Generate), utilizando documentos relacionados aos produtos da Amazon.\n",
        "- A partir do prompt formado pela pergunta do usuário e dos dados retornados do RAG, o modelo deverá gerar uma resposta baseada na pergunta do usuário e nos dados provenientes do RAG, incluindo as fontes.\n",
        "\n",
        "# Passos para a aplicação de fine-tuning no Modelo\n",
        "\n",
        "O The AmazonTitles-1.3MM consiste em consultas textuais reais de usuários e títulos associados de produtos relevantes encontrados na Amazon, medidos por ações implícitas ou explícitas dos usuários.\n",
        "1.   Preparação do Dataset <br>\n",
        "    - Download do dataset AmazonTitles-1.3MM.\n",
        "    - Prepare os dados para o fine-tuning, garantindo que estejam organizados de maneira adequada para o treinamento do modelo.\n",
        "    - Limpe e pré-processe os dados conforme necessário para o modelo escolhido.\n",
        "2.  Execução do Fine-Tuning <br>\n",
        "    - Execute o fine-tuning do foundation model selecionado utilizando o dataset preparado.\n",
        "    - Documente o processo de fine-tuning, incluindo os parâmetros utilizados e qualquer ajuste específico realizado no modelo.\n",
        "3.  Configuração da Integração RAG\n",
        "    - Configure uma integração RAG (Retrieve-and-Generate) para fornecer contexto ao modelo a partir dos documentos relacionados aos produtos da Amazon.\n",
        "    - Certifique-se de que a integração esteja funcionando corretamente para recuperar e fornecer dados contextuais ao modelo.\n",
        "4.  Geração de Respostas\n",
        "    - Configure o modelo treinado para receber perguntas dos usuários.\n",
        "    - Quando uma pergunta for recebida, utilize a integração RAG para recuperar informações relevantes do dataset AmazonTitles-1.3MM.\n",
        "    - Combine a pergunta do usuário e os dados retornados do RAG para formar um prompt completo.\n",
        "    - O modelo deverá gerar uma resposta baseada na pergunta do usuário e nos dados provenientes do RAG, incluindo as fontes fornecidas."
      ],
      "metadata": {
        "id": "VeZWsv7dgWB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação do Dataset\n",
        "- Download do dataset AmazonTitles-1.3MM.\n",
        "- Prepare os dados para o fine-tuning, garantindo que estejam organizados de maneira adequada para o treinamento do modelo.\n",
        "- Limpe e pré-processe os dados conforme necessário para o modelo escolhido."
      ],
      "metadata": {
        "id": "XOxaifA2gYov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH = '/content/drive/MyDrive/TheAmazonTitles'\n",
        "FINE_TUNING_PATH = f'{FOLDER_PATH}/fine-tuning'\n",
        "URLDATA_GOOGLEDRIVE = f'https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK'"
      ],
      "metadata": {
        "id": "Ofzc1OxJyKIN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AdKF60IPyN7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ded3ef5-9288-4059-dd00-5b9d375ea8e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que os dados disponibilizados para construção do modelo encontram-se em um link do Google Drive, se faz necessário obter alguma estratégia para manuseio.\n",
        "No modelo, utilizando a lib gdown, é feito o download a partir do link e os arquivos extraídos para uma pasta em MyDrive.\n",
        "Se faz necessária essa estratégia pois garante que, ao encerrar a sessão, os dados não são perdidos, gerando a necessidade de realizar o download e extração novamente."
      ],
      "metadata": {
        "id": "YEBPooNLoqGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "if not os.path.exists(FOLDER_PATH):\n",
        "    os.makedirs(FOLDER_PATH)\n",
        "\n",
        "zip_file = f'{FOLDER_PATH}/LF-Amazon-1.3M.zip'\n",
        "\n",
        "gdown.download(URLDATA_GOOGLEDRIVE, zip_file, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(FOLDER_PATH)\n",
        "\n",
        "print(\"Files successfully extracted and saved to the Google Drive directory!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcIdWd77hNwG",
        "outputId": "f1886cd6-98d5-4d11-e91a-f3dfc69fa64a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK\n",
            "From (redirected): https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK&confirm=t&uuid=0659c183-dab2-4dcc-b2dd-051d78236a4a\n",
            "To: /content/drive/MyDrive/TheAmazonTitles/LF-Amazon-1.3M.zip\n",
            "100%|██████████| 890M/890M [00:43<00:00, 20.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files successfully extracted and saved to the Google Drive directory!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estrutura do Dowload de AmazonTitles-1.3MM é a seguinte:\n",
        "\n",
        "- pasta.zip e a mesma abriga os seguintes arquivos:\n",
        "    - filter_labels_train.txt (padrão do conteúdo do arquivo: número número)\n",
        "    - filter_labels_test.txt (padrão do conteúdo do arquivo: número número)\n",
        "    - tst.json.gz (padrão do conteúdo do arquivo: objeto json inline)\n",
        "    - trn.json.gz (padrão do conteúdo do arquivo: objeto json inline)\n",
        "    - lbl.json.gz (padrão do conteúdo do arquivo: objeto json inline)\n",
        "\n",
        "Todos os arquivos acima passam das 100 mil linhas cada um. <br>\n",
        "Para lidar com arquivos grandes como os .json.gz, carregar todo o conteúdo na memória pode ser inviável por falta de recursos computacionais. <br>\n",
        "A abordagem adotada foi aplicar o algoritmo de Reservoir Sampling: permite selecionar uma amostra aleatória de tamanho fixo de um fluxo de dados de tamanho desconhecido sem carregar todo o conteúdo do arquivo em memória."
      ],
      "metadata": {
        "id": "2SLiMyWNp4HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import random\n",
        "import json\n",
        "\n",
        "def reservoir_sampling_gz_json_with_indices(file_path, sample_size):\n",
        "    sample = []\n",
        "    indices = []\n",
        "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                if i < sample_size:\n",
        "                    sample.append(obj)\n",
        "                    indices.append(i)\n",
        "                else:\n",
        "                    j = random.randint(0, i)\n",
        "                    if j < sample_size:\n",
        "                        sample[j] = obj\n",
        "                        indices[j] = i\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON on line {i}: {e}\")\n",
        "    return sample, indices\n"
      ],
      "metadata": {
        "id": "1xPjWnAiyUma"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho das amostras desejadas\n",
        "sample_size_train = 4000\n",
        "sample_size_test = 1000\n",
        "sample_size_label = 4000\n",
        "\n",
        "# Realiza a amostragem dos arquivos gzip de treinamento e teste\n",
        "train_sample, train_indices = reservoir_sampling_gz_json_with_indices(f'{FOLDER_PATH}/LF-Amazon-1.3M/trn.json.gz', sample_size_train)\n",
        "test_sample, test_indices = reservoir_sampling_gz_json_with_indices(f'{FOLDER_PATH}/LF-Amazon-1.3M/tst.json.gz', sample_size_test)\n",
        "\n",
        "print(len(train_sample))\n",
        "print(len(test_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGrHeGY1i9d9",
        "outputId": "1d724918-da7f-43e5-aa81-8769653293ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a extração dos dados de treino e teste, é o momento de extrair o conteúdo dos arquivos de filter_labels para indexar com os dados extraídos anteriormente. E assim criar um mapeamento dos dados com base nos filtros."
      ],
      "metadata": {
        "id": "6Ov7k4v0sb5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar os labels correspondentes aos índices\n",
        "def load_labels_by_indices(file_path, indices):\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    for idx in indices:\n",
        "        if idx < len(lines):\n",
        "            labels.append(lines[idx].strip().split())\n",
        "        else:\n",
        "            labels.append([])\n",
        "    return labels\n",
        "\n",
        "filter_labels_train_sample = load_labels_by_indices(f'{FOLDER_PATH}/LF-Amazon-1.3M/filter_labels_train.txt', train_indices)\n",
        "filter_labels_test_sample = load_labels_by_indices(f'{FOLDER_PATH}/LF-Amazon-1.3M/filter_labels_test.txt', test_indices)\n",
        "\n",
        "print(len(filter_labels_train_sample))\n",
        "print(filter_labels_train_sample[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ka_5mdjW_j",
        "outputId": "17fd32ee-4a17-4120-b17f-56b7f12c8e76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "[[], [], [], [], [], ['1176652', '736535'], [], ['263600', '445493'], [], [], [], [], [], [], [], [], [], [], ['10324', '41505'], ['395171', '351456'], [], [], [], [], [], ['805206', '712900'], [], ['820313', '687670'], [], [], ['324437', '205387'], [], [], ['503218', '223410'], [], [], [], [], [], ['1505094', '454723'], [], [], [], ['268242', '310523'], [], [], [], [], ['581112', '566235'], [], ['1151487', '240581'], [], [], [], [], ['29579', '14897'], [], [], [], ['1487196', '295488'], [], [], [], [], [], [], ['1834344', '1282492'], ['92548', '309315'], [], ['10643', '67692'], [], ['1799307', '383888'], [], [], [], ['370244', '55135'], ['1945255', '837203'], ['45307', '197579'], ['1455401', '480423'], [], [], ['509003', '337154'], ['807336', '841473'], ['1126364', '1145116'], [], [], ['1227244', '1039860'], ['1685034', '687219'], ['493712', '119049'], [], [], ['1049443', '882525'], [], [], ['2054566', '433307'], [], ['1317406', '393311'], [], [], ['1302325', '1042213']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando a limpeza dos dados\n",
        "\n",
        "É de extrema importância a etapa de limpeza, pois é a partir dela que geramos inputs sem ruídos para o treinamento do modelo.\n",
        "Abaixo, foi implementada limpeza de HTML Entities nos campos de texto, além de outros tratamentos necessários como remoção de novas linhas e múltiplos espaços."
      ],
      "metadata": {
        "id": "wwRA0xHts9fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import html\n",
        "\n",
        "def unescape_html_entities(text):\n",
        "    text = html.unescape(text)\n",
        "    def replace_hex_entity(match):\n",
        "        code_point = int(match.group(1), 16)\n",
        "        return chr(code_point)\n",
        "\n",
        "    text = re.sub(r'&#x([0-9A-Fa-f]+);', replace_hex_entity, text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = unescape_html_entities(text)\n",
        "    text = text.replace('’', \"'\")\n",
        "    # Remove caracteres especiais\n",
        "    text = re.sub(r\"[^A-Za-z0-9',. ]+\", '', text)\n",
        "    # Remove novas linhas e espaços extras\n",
        "    text = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
        "    # Remove múltiplos espaços\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "YRQ93w7Ujj1a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "# Processa uma lista de amostras, limpando textos e associando rótulos. Remove itens que não possuem 'title' ou 'uid'.\n",
        "def process_samples(sample_data: List[Dict], filter_labels_sample: List) -> List[Dict]:\n",
        "    processed_samples = []\n",
        "    total_items = len(sample_data)\n",
        "    total_labels = len(filter_labels_sample)\n",
        "\n",
        "    for idx, item in enumerate(sample_data):\n",
        "        title = item.get('title', '').strip()\n",
        "        uid = item.get('uid', '').strip()\n",
        "        content = item.get('content', '').strip()\n",
        "\n",
        "        if not title or not uid or not content:\n",
        "            continue  # Ignora itens com 'title' ou 'uid' vazios ou 'content' vazios\n",
        "\n",
        "        if title == content:\n",
        "            continue  # Ignora itens com 'title' == 'content'\n",
        "\n",
        "        # Limpeza dos campos de texto\n",
        "        item['title'] = clean_text(title)\n",
        "        item['content'] = clean_text(content)\n",
        "\n",
        "        # Associação de rótulos\n",
        "        if idx < len(filter_labels_sample):\n",
        "            item['labels'] = filter_labels_sample[idx]\n",
        "        else:\n",
        "            item['labels'] = []\n",
        "\n",
        "        processed_samples.append(item)\n",
        "\n",
        "    return processed_samples"
      ],
      "metadata": {
        "id": "kfnhgAtljZz8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_train_sample = process_samples(train_sample, filter_labels_train_sample)\n",
        "clean_test_sample = process_samples(test_sample, filter_labels_test_sample)\n",
        "\n",
        "print(clean_train_sample[0])\n",
        "print(clean_test_sample[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DTjSSq9jb_4",
        "outputId": "8dff7d47-813c-48de-8a3e-8a2ac71f95d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uid': 'B003JOVL70', 'title': 'Instructor Size Underwater Writing Dive Slates 8 x 10, 8 x 11 Slate SL04', 'content': 'ideal for note taking or a back up communication device.', 'target_ind': [150234, 600808], 'target_rel': [1.0, 1.0], 'labels': []}\n",
            "{'uid': 'B007Y9NRI2', 'title': 'Aimo Wireless LGLM272PCDI123 Bling Brilliance Premium Grade Diamond Case for LG Rumor ReflexFreedomConverseExpression C395 Retail Packaging Pink Leopard', 'content': 'The Pink Leopard Premium Executive Diamond Case by Aimo Wireless for your LG Rumor ReflexFreedomConverseExpression C395 is a durable slim fit SnapOn case made to add luxury, style and protection to your phone. The case is constructed of durable hard plastic adorned with beautiful rhinestone crystals to give it a unique, oneofakind design and protection to match. The Pink Leopard Executive diamond design really gives the cover brilliance and shine, complementing the look and feel of your LG Rumor ReflexFreedomConverseExpression C395. Accurate cutouts provide full access to all the functions of your phone including all ports, charging jack and screen, while a hard plastic construction provides protection from scratches, dents and other types of damage. Showcase your personal style and dress your phone with this brilliant dazzling case.', 'target_ind': [1040358, 1169445, 1173407], 'target_rel': [1.0, 1.0, 1.0], 'labels': ['42216', '329687']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução do Fine-Tuning\n",
        "- Execute o fine-tuning do foundation model selecionado utilizando o dataset preparado.\n",
        "- Documente o processo de fine-tuning, incluindo os parâmetros utilizados e qualquer ajuste específico realizado no modelo."
      ],
      "metadata": {
        "id": "f_RXsRDMkBAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XFPNYFIDkPl2",
        "outputId": "8bbd70da-790e-48a7-98c4-278f25b2e59f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esse modelo foi escolhido o distilgpt2 por ser uma versão menor e mais leve do GPT-2, projetada para ser mais eficiente em termos de recursos. Como o modelo é para fins acadêmicos, é o suficiente para aplicar as lógicas necessárias.\n",
        "E para treinar esse modelo, são necessárias algumas etapas prévias:\n",
        "\n",
        "1. Preparação dos Dados de Treinamento, processando amostras de dados limpos para criar pares de \"prompt\" e \"completion\".\n",
        "2. Criação de um Dataset, convertendo essas amostras em um formato adequado para treinamento utilizando a biblioteca datasets."
      ],
      "metadata": {
        "id": "U6NUF5JpwqKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_data = clean_train_sample\n",
        "test_data = clean_test_sample\n",
        "\n",
        "# Prepara os dados para o dataset\n",
        "def get_training_samples(sample):\n",
        "    training_samples = []\n",
        "    for item in sample:\n",
        "        # Integração das labels no prompt\n",
        "        prompt = f\"Category: {item['labels']}\\nTitle: {item['title']}\\nDescription:\"\n",
        "        completion = item['content']\n",
        "        training_samples.append({'prompt': prompt, 'completion': completion})\n",
        "    return training_samples\n",
        "\n",
        "# Cria Dataset\n",
        "train_dataset = Dataset.from_list(get_training_samples(train_data))\n",
        "test_dataset = Dataset.from_list(get_training_samples(test_data))"
      ],
      "metadata": {
        "id": "qxerHTK0zJyp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daUJZ15e0NGv",
        "outputId": "67830488-4836-48a9-9ca8-5f2c7122e2c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'completion'],\n",
              "    num_rows: 2494\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Configuração e Carregamento do Modelo e Tokenizer, através do modelo pré-treinado distilgpt2 da biblioteca transformers. Ajusta o tokenizer e o modelo para garantir que estejam alinhados em termos de tokens.\n",
        "4. Tokenização dos Dados, que transforma os textos de entrada em tokens numéricos que o modelo pode processar. Em linhas gerais, prepara os dados para serem alimentados no modelo durante o treinamento."
      ],
      "metadata": {
        "id": "8KcJK46AxSQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = 'distilgpt2'\n",
        "\n",
        "# Carrega o tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "'''\n",
        "Faz a atribuição do pad_token.\n",
        "O GPT-2 originalmente não possui um token de padding,\n",
        "e essa substituição ajuda na tokenização de sequências de comprimento fixo.\n",
        "'''\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Carrega o modelo escolhido\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))  # Redimensiona o Token Embeddings\n",
        "\n",
        "# Função de tokenização\n",
        "def tokenize_function(examples):\n",
        "    # Concatena 'prompt' e 'completion' para cada item\n",
        "    inputs = [prompt + \" \" + completion for prompt, completion in zip(examples['prompt'], examples['completion'])]\n",
        "    # Tokeniza os inputs\n",
        "    tokenized_inputs = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,       # Garante que sequências mais longas que max_length sejam truncadas.\n",
        "        padding='max_length',  # Adiciona padding para que todas as sequências tenham o mesmo comprimento\n",
        "        max_length=128,        # Define o comprimento máximo das sequências tokenizadas.\n",
        "    )\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "20968348f74140429922b6088608995b",
            "9429c9c5046c43b78fff1ea0a62a9381",
            "b18b4ba9a4dc4001931b597bafd6a23c",
            "2f0e69c760674f8c96e479e2adffd2ee",
            "cf2b700ee28b4526836f64099935753f",
            "a6ba2a7c5b7d45ae94be3acae56f504e",
            "6015fedff32d484d91a0a68607aca932",
            "6fe11443601c48fd9e8415ad155015dc",
            "6243ca6b4b37486284229f5874cb37a9",
            "d9f5bb9e6044431a9b5ecc1e3dacc511",
            "f985d323bc4442c19c0bd8bf7f3b1702"
          ]
        },
        "id": "6s2LUzTE0R3S",
        "outputId": "bdce09d6-9358-484a-8d4a-bc98066a648b",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2494 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20968348f74140429922b6088608995b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r-xc9WhlAax",
        "outputId": "63233bfa-36fb-40ee-d71f-4008d9111bc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'completion', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 2494\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "'''\n",
        "Configura um objeto responsável por preparar os dados em lotes para o\n",
        "treinamento do modelo de linguagem.\n",
        "'''\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False # Masked Language Modeling = False / Causal Language Modeling = True.\n",
        ")\n"
      ],
      "metadata": {
        "id": "Owh9-Zxw0dNN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Configuração dos argumentos para Treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f'{FINE_TUNING_PATH}/training_args',\n",
        "    num_train_epochs=3,  # Número de vezes que o conjunto de dados completo será passado pelo modelo durante o treinamento.\n",
        "    per_device_train_batch_size=4, # Tamanho do lote por dispositivo (GPU/CPU) durante o treinamento.\n",
        "    save_total_limit=2, # Número máximo de checkpoints a serem mantidos. Os mais antigos são removidos quando o limite é excedido.\n",
        "    logging_steps=100, # Intervalo de passos entre cada registro (log) de métricas de treinamento.\n",
        "    learning_rate=5e-5          # Ajustar a taxa de aprendizado\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Inicializando treino dos dados com o modelo distilgpt2\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "xvgEUn3P1E-7",
        "outputId": "e15d50c1-972b-4898-93d5-73cfcee03c10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1872' max='1872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1872/1872 04:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.369200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.283800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.269300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.184300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>4.191600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.958500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.901200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.875500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.959000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.894700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>3.805000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.749300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.724200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>3.747600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>3.716400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.763500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1872, training_loss=3.955227110120985, metrics={'train_runtime': 244.2112, 'train_samples_per_second': 30.637, 'train_steps_per_second': 7.665, 'total_flos': 244377785991168.0, 'train_loss': 3.955227110120985, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tendência geral de diminuição da perda indica que o modelo está aprendendo e melhorando seu desempenho ao longo do treinamento.\n",
        "A estabilização da perda sugere que o modelo está alcançando um ponto de convergência."
      ],
      "metadata": {
        "id": "yacrtkwqz1S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando componentes do Treino após a execução para não retreinar a cada queda de sessão\n",
        "trainer.save_model(f'{FINE_TUNING_PATH}/trainer-result')\n",
        "model.save_pretrained(f'{FINE_TUNING_PATH}/model-tokenizer')\n",
        "tokenizer.save_pretrained(f'{FINE_TUNING_PATH}/model-tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLybzx-Q6NnH",
        "outputId": "a6fda3a7-7342-4595-c1ad-95a92ac65df7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/vocab.json',\n",
              " '/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/merges.txt',\n",
              " '/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/TheAmazonTitles/fine-tuning/model-tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração da Integração RAG\n",
        "- Configure uma integração RAG (Retrieve-and-Generate) para fornecer contexto ao modelo a partir dos documentos relacionados aos produtos da Amazon.\n",
        "- Certifique-se de que a integração esteja funcionando corretamente para recuperar e fornecer dados contextuais ao modelo.\n"
      ],
      "metadata": {
        "id": "ZaWCWq9rlha0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install sentence_transformers faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T7_0bFSQmxN3",
        "outputId": "77b69330-9b05-4b8c-916b-fb8c769beea5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.126)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.126)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.68)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "clean_train_sample_df = pd.DataFrame(clean_train_sample)\n",
        "clean_train_sample_df.reset_index(drop=True, inplace=True)\n",
        "clean_train_sample_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LrFc_wp7QsGd",
        "outputId": "54a1cfc5-ac6e-4c96-9536-4522842d3e92"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          uid                                              title  \\\n",
              "0  B003JOVL70  Instructor Size Underwater Writing Dive Slates...   \n",
              "1  B003KRRAAI                   Popup Towel Mini Wipes Bag of 10   \n",
              "2  B000QV0MA6                          Gumballs Sugar Free 16oz,   \n",
              "3  1484843010           Hard Math for Elementary School Workbook   \n",
              "4  0415420830                              Paradoxes from A to Z   \n",
              "\n",
              "                                             content  \\\n",
              "0  ideal for note taking or a back up communicati...   \n",
              "1  PopUp Towels are perfect for any use. These al...   \n",
              "2  Carousel Sugar Free Gumballs .62Carousel sugar...   \n",
              "3  Glenn Ellison is the Gregory K. Palm Professor...   \n",
              "4  'Selfcontained courses in paradox are not usua...   \n",
              "\n",
              "                                          target_ind  \\\n",
              "0                                   [150234, 600808]   \n",
              "1                                           [457842]   \n",
              "2  [12384, 46466, 46468, 51979, 55729, 106099, 11...   \n",
              "3  [7512, 14785, 18541, 18545, 18620, 18657, 1867...   \n",
              "4                                            [72776]   \n",
              "\n",
              "                                          target_rel             labels  \n",
              "0                                         [1.0, 1.0]                 []  \n",
              "1                                              [1.0]                 []  \n",
              "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                 []  \n",
              "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  [1176652, 736535]  \n",
              "4                                              [1.0]   [263600, 445493]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb26f846-8330-46aa-b02a-644d80cf8359\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>target_ind</th>\n",
              "      <th>target_rel</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B003JOVL70</td>\n",
              "      <td>Instructor Size Underwater Writing Dive Slates...</td>\n",
              "      <td>ideal for note taking or a back up communicati...</td>\n",
              "      <td>[150234, 600808]</td>\n",
              "      <td>[1.0, 1.0]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B003KRRAAI</td>\n",
              "      <td>Popup Towel Mini Wipes Bag of 10</td>\n",
              "      <td>PopUp Towels are perfect for any use. These al...</td>\n",
              "      <td>[457842]</td>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000QV0MA6</td>\n",
              "      <td>Gumballs Sugar Free 16oz,</td>\n",
              "      <td>Carousel Sugar Free Gumballs .62Carousel sugar...</td>\n",
              "      <td>[12384, 46466, 46468, 51979, 55729, 106099, 11...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1484843010</td>\n",
              "      <td>Hard Math for Elementary School Workbook</td>\n",
              "      <td>Glenn Ellison is the Gregory K. Palm Professor...</td>\n",
              "      <td>[7512, 14785, 18541, 18545, 18620, 18657, 1867...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "      <td>[1176652, 736535]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0415420830</td>\n",
              "      <td>Paradoxes from A to Z</td>\n",
              "      <td>'Selfcontained courses in paradox are not usua...</td>\n",
              "      <td>[72776]</td>\n",
              "      <td>[1.0]</td>\n",
              "      <td>[263600, 445493]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb26f846-8330-46aa-b02a-644d80cf8359')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb26f846-8330-46aa-b02a-644d80cf8359 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb26f846-8330-46aa-b02a-644d80cf8359');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3a9e45f-6aa0-4fd3-abf9-003337699188\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3a9e45f-6aa0-4fd3-abf9-003337699188')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3a9e45f-6aa0-4fd3-abf9-003337699188 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_train_sample_df",
              "summary": "{\n  \"name\": \"clean_train_sample_df\",\n  \"rows\": 2494,\n  \"fields\": [\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2494,\n        \"samples\": [\n          \"B004W29I4G\",\n          \"B0057D8UYI\",\n          \"B004XD2XD2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2494,\n        \"samples\": [\n          \"eForCity High Speed HDMI Cable with Ethernet ,Type D Micro MM Cable ,10FT\",\n          \"Let Me Out of Here\",\n          \"Vilano Performance 700C21 Speed Shimano Hybrid Flat Bar Commuter Road Bike\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2486,\n        \"samples\": [\n          \"Hawaiian chef and restaurant owner Choy Sam Choy's Island Flavors brings to the table his island tales and food with this delightful new volume. Filled with anecdotes and photographs of his visits and the food memories associated with each voyage, he travels as far south as New Zealand, taking in along the way such farreaching islands as Samoa, Tonga and Tahiti. Starting with a very full section covering the ingredients used throughout the book, Choy discusses the various culinary influences from the Chinese in Fiji and Samoa and the French in the Marquesas, to the Indian British impact throughout the regions. Whether it's the GingerScallion Fried Rice from Fiji, or the piquant sweetsour flavors of the Kau'u OrangeGinger Chicken from Hawaii, the recipes offer simple techniques and full fresh flavors. Cooks will recognize the many staple ingredients such as orange juice and coconut milk, which appear regularly throughout the book in such combinations as Baked Snapper with OrangeCoconut Sauce of the Marquesas, or Samoan Coconut Rice and Baked Banana Vanilla Custard from Tahiti. In bringing together the groups of recipes, Choy conveys a light yet satisfying cuisine that enchants the taste buds and expands one's knowledge of Polynesian cuisine.Copyright 2002 Cahners Business Information, Inc.\",\n          \"Show your support with this great embroidered Army Veteran Cap. Stylish with its high definition 3D embroidery. Adjustable to fit.\",\n          \"1X High Speed HDMI Cable with Ethernet, Type A to D Micro M M , 10FT, V2Connect your portable DVs, Cameras, Game Consoles to your HDTV with a true HD connectionA premium quality HDMI HDMI micro cable suitable for use with camcordersFeatures connectors, strain relief and Mylar foil shieldingCable constructed using the high quality material for best contact connection between HDMI equipmentsFully HDCP compliant to provide highest level of signal qualityFully compatible with High Speed HDMI with Ethernet specification Version 1.4A superb cable with excellent audiovisual transfer properties that deliver signal without compromising purity and balanceFeaturesConnectors for highest signal transfer rate and resistance in corrosionLarge gauge PVC jacket provides maximum shielding against wear and tear and extreme temperaturesReinforced quadlayer braided shielding and Mylarfoil shielding provides utmost protection against RF and EM interferenceMolded strainrelief design lessens plugsocket pressureDesigned to meet all HDMI standardsSupports 480i, 480p, 720p, 1080i, 1080p resolutionColor BlackLength 10 FTVersion 2Suggested Applications HDTVs, HD DVs, Cameras, Game Consoles with HDMI and HDMI Type D Micro ConnectorsNOTE Even though HDMI cables support Hot Plug Detection, improper usage might result in resetting restarting both devices, or even may cause damage to the devices. Therefore, we do not suggest Hot Plug action for any HDMI cables. Please make sure both input and output devices are off when plugging or unplugging HDMI cables.Compatible WithBlackBerryZ10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_ind\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_rel\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversão DataFrame para Document do LangChain\n",
        "\n",
        "Organizar os dados em objetos Document facilita o gerenciamento e a manipulação dos documentos, especialmente quando se trata de adicionar metadados que podem ser úteis para buscas e filtragens futuras.\n",
        "Além de que a estruturação dos documentos de forma consistente permite que os embeddings sejam gerados de maneira uniforme, garantindo que todas as informações relevantes (como título e UID) estejam disponíveis para uso posterior."
      ],
      "metadata": {
        "id": "Mw5ejUxZ1IMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.docstore.document import Document\n",
        "from tqdm import tqdm\n",
        "\n",
        "def create_documents(df):\n",
        "    \"\"\"\n",
        "    Converte as entradas do DataFrame em objetos Document do LangChain\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Criando Objetos Documentos\"):\n",
        "        content = row['content']\n",
        "        metadata = {'uid': row['uid'], 'title': row['title']}\n",
        "        documents.append(Document(page_content=content, metadata=metadata))\n",
        "    return documents\n",
        "\n",
        "documents = create_documents(clean_train_sample_df)\n",
        "print('\\n',documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkuAd458Jox0",
        "outputId": "30021ce1-e760-493a-c82c-ad15d40977ff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Criando Objetos Documentos: 100%|██████████| 2494/2494 [00:01<00:00, 1954.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " page_content='ideal for note taking or a back up communication device.' metadata={'uid': 'B003JOVL70', 'title': 'Instructor Size Underwater Writing Dive Slates 8 x 10, 8 x 11 Slate SL04'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação de Embeddings e Retriever\n",
        "Embeddings transformam texto em vetores numéricos que capturam semântica e contexto, permitindo que algoritmos de busca e recuperação encontrem similaridades entre diferentes textos de forma eficiente. E a lib FAISS permite indexar e buscar rapidamente vetores de alta dimensão, tornando-o ideal para aplicações que exigem buscas por similaridade em grandes conjuntos de dados, como sistemas de recomendação, busca semântica e recuperação de informações.\n",
        "\n",
        "`all-MiniLM-L6-v2` foi escolhido por ser conhecido pela eficiência em produzir embeddings de alta qualidade para tarefas de processamento de linguagem natural.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GPJObev21xNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model_name=\"all-MiniLM-L6-v2\""
      ],
      "metadata": {
        "id": "NXKG0YR3PPaT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "def load_faiss_retriever():\n",
        "    \"\"\"\n",
        "    Carrega o índice FAISS e configura o retriever\n",
        "    \"\"\"\n",
        "    embeddings = SentenceTransformerEmbeddings(model_name=embedding_model_name)\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}) # Recupera 5 documentos\n",
        "    return retriever\n",
        "\n",
        "retriever = load_faiss_retriever()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5VeN0o5KOID",
        "outputId": "6939c61c-1f04-4b92-be5a-fc7e107f056d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "<ipython-input-25-618e0abc1797>:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=embedding_model_name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se o retriver está hábil a consultar Documentos contextualizados com o input fornecido."
      ],
      "metadata": {
        "id": "XLssMzlR4PZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"Tell me something about Marvel Movies\")[:10]\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-hXNeLnM7u5",
        "outputId": "94330bda-5f80-4d7a-d726-ac091485d10f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-bff30c2fe6ac>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"Tell me something about Marvel Movies\")[:10]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'uid': 'B004NE4KX2', 'title': 'Marvel Superhero Squad Series 20 Mini 3 Inch Figure 2Pack Iron Man Red Hulk'}, page_content='Spring into adventure with the worlds greatest collection of Super Heroes. The mightiest Marvel heroes are ready to save the day with their amazing abilities and super powers. Build your team and join in the battle with the Marvel Super Hero Squad Gear up for adventure with this fun duo Pair of chunky figures includes SpiderMan and Moon Knight figures.'),\n",
              " Document(metadata={'uid': 'B00DDVY6C6', 'title': 'Gentle Giant SpiderMan Mini Bust, RedBlue'}, page_content=\"Few heroes are as synonymous with Marvel than SpiderMan. For over 50 years now, the WallCrawler has dispensed his unique form of wisecracking, webbed justice on the streets of New York and throughout the Marvel Universe. Although he has worn many different uniforms over the years, the classic redandblue suit will always be the first thing fans imagine when they think of SpiderMan. Now, Gentle Giant is proud to honor that heritage with the SpiderMan Mini Bust. Digitally sculpted, then coldcast in the highest quality polystone and handpainted by the master artisans at Gentle Giant, this limited edition bust captures the essence of Peter Parker's alterego perfectly. Each piece comes individually numbered and includes a matching certificate of authenticity. Look out. Here comes the SpiderMan.\"),\n",
              " Document(metadata={'uid': 'B00005O6SZ', 'title': 'Marvel Select Origin Wolverine'}, page_content=\"A Diamond Select Release Toy Biz and Diamond Select join forces once again to bring you Logan, a.k.a. Wolverine, from the controversial, longawaited Origin of the popular XMen character. Captured 'in the hunt', Logan bounds through the deep forest on the trail of a deer, three wolves at his side. Logan runs with the pack as this awesome new Marvel Select figure, sculpted by Shawn Nagle and measuring 7' in height. The figure comes complete with forest display base and three wolves. Highly detailed and featuring limited articulation, this figure will not be available in massmarket outlets, and is meant for the discriminating Marvel collector. All Marvel Select figures are in scale with one another and can be displayed with other Marvel Select figure accessories if desired. Origin Wolverine is the sixth figure in Diamond Select's line of monthly specialty market figures Deluxe blister card packaging.\"),\n",
              " Document(metadata={'uid': '0240517385', 'title': 'On Film Editing An Introduction to the Art of Film Construction'}, page_content='Editing is the creative force of filmic reality. So Dmytryk, director of the American classic The Caine Mutiny begins this little book, which he hopes will aid film directors and editors in perfecting their art. It is informative for general audiences as well, demonstrating how deeply the experience of any film relies on the creativity and versatility of its editor.'),\n",
              " Document(metadata={'uid': '078515129X', 'title': 'Captain America Man Out of Time'}, page_content=\"Mark Waid is a legendary comic book writer and editor best known for his long tenure as writer on Captain America in the 1990's as well as his 8 year run on the Flash for DC Comics.This text refers to an out of print or unavailable edition of this title.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reutilização de Modelos Fine-Tuned\n",
        "Utiliza o modelo e tokenizer treinados previamente com o model `distilgpt2`. Permitindo o aproveitamento do conhecimento adquirido durante o fine-tuning, garantindo que o modelo esteja adaptado às necessidades específicas."
      ],
      "metadata": {
        "id": "zJOPxtDj2d8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
        "import torch\n",
        "import re\n",
        "\n",
        "model_path=f'{FINE_TUNING_PATH}/model-tokenizer'\n",
        "\n",
        "def load_finetuned_model():\n",
        "    \"\"\"\n",
        "    Carrega o modelo GPT-2 ajustado e o tokenizer\n",
        "    \"\"\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Assegura que o token de padding esteja definido\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "    # Move o modelo para GPU se disponível\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer, device\n",
        "\n",
        "# Inicializa o modelo, o tokenizer e o dispositivo\n",
        "model, tokenizer, device = load_finetuned_model()"
      ],
      "metadata": {
        "id": "Assn21kvKr2u"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa o pipeline de geração de texto\n",
        "nlp = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1  # Usa GPU se disponível\n",
        ")"
      ],
      "metadata": {
        "id": "TppO4xK_WMOW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Personalizando as Respostas com o RAG"
      ],
      "metadata": {
        "id": "IUAdAhA94lpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E abaixo, os métodos responsáveis pela captação dos documentos e geração das respostas das questões inputadas pelo usuário.\n",
        "\n",
        "Com esses métodos é possível:\n",
        "1. Fornecer ao modelo um contexto relevante e conciso, aumentando a probabilidade de gerar respostas precisas e informativas.\n",
        "2. Truncar o contexto garante que o prompt completo (incluindo a pergunta e o contexto) não exceda o limite.\n",
        "3. Retornar as fontes permite que você saiba de onde as informações foram extraídas, o que é útil para verificação e transparência."
      ],
      "metadata": {
        "id": "j7xrrw6L3lxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_documents=10\n",
        "max_context_tokens=500\n",
        "max_new_tokens=128\n",
        "\n",
        "\n",
        "def get_relevant_context(question):\n",
        "    \"\"\"\n",
        "    Recupera o contexto relevante para a pergunta dada usando o retriever.\n",
        "    \"\"\"\n",
        "    # Recupera documentos relevantes\n",
        "    docs = retriever.get_relevant_documents(question)[:max_documents]\n",
        "\n",
        "    # Combina o conteúdo dos documentos recuperados\n",
        "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # Trunca o contexto se exceder max_context_tokens\n",
        "    context_tokens = tokenizer.tokenize(context)\n",
        "    if len(context_tokens) > max_context_tokens:\n",
        "        context_tokens = context_tokens[:max_context_tokens]\n",
        "        context = tokenizer.convert_tokens_to_string(context_tokens)\n",
        "\n",
        "    sources = [doc.metadata for doc in docs]\n",
        "    return context, sources\n",
        "\n",
        "def remove_repetitions(text):\n",
        "    \"\"\"\n",
        "    Remove frases repetidas consecutivas do texto.\n",
        "    \"\"\"\n",
        "    # Padrão de regex para encontrar frases repetidas consecutivamente\n",
        "    pattern = re.compile(r'(.+?)(?:\\s+\\1)+', re.IGNORECASE)\n",
        "    return pattern.sub(r'\\1', text)\n",
        "\n",
        "def generate_response(question):\n",
        "    \"\"\"\n",
        "    Gera uma resposta à pergunta do usuário usando a integração RAG.\n",
        "    \"\"\"\n",
        "    # Recupera contexto relevante e fontes\n",
        "    context, sources = get_relevant_context(question)\n",
        "\n",
        "    prompt = f\"Question: {question}\\nContext: {context}\\nAnswer:\"\n",
        "\n",
        "    # Gera a resposta usando o pipeline\n",
        "    response = nlp(\n",
        "        prompt,\n",
        "        max_new_tokens=max_new_tokens, # Define o número de novos tokens a serem gerados\n",
        "        temperature=0.3,            # Ajuste para criatividade\n",
        "        top_k=50,                   # Controla diversidade através da amostragem top-k\n",
        "        top_p=0.9,                  # Controla diversidade via amostragem nucleus (valor corrigido)\n",
        "        repetition_penalty=2.0,     # Penaliza frases repetidas\n",
        "        no_repeat_ngram_size=5,     # Previne repetição de n-grams\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated_text = response[0]['generated_text']\n",
        "    # Remove o prompt do texto gerado para obter a resposta\n",
        "    answer = generated_text[len(prompt):].strip()\n",
        "    # Limpa a resposta removendo repetições\n",
        "    answer = remove_repetitions(answer)\n",
        "    formatted_sources = \"\\n\".join([f\"- UID: {source['uid']}, Title: {source['title']}\" for source in sources])\n",
        "\n",
        "    return f\"\\n**Answer:**\\n{answer}\\n\\n**Sources:**\\n{formatted_sources}\""
      ],
      "metadata": {
        "id": "3Y2Pfl_JM3RJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"Tell me something about Asian food\")[:10]\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8ScDBJUTZ8G",
        "outputId": "da08cbb0-4544-4c4f-aad8-9819b4e8e164"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'uid': 'B006S2SJKM', 'title': 'HuangFeiHong Spicy Snack Peanuts 3.8 oz 110G 8 bags Pack of 8'}, page_content='HuangFeiHong Spicy Snack Peanuts 8 3.8 oz 110G 8 bags'),\n",
              " Document(metadata={'uid': '0786864753', 'title': \"Sam Choy's Polynesian Kitchen More Than 150 Authentic Dishes from One of the World's Most Delicious and Overlooked Cuisines\"}, page_content=\"Hawaiian chef and restaurant owner Choy Sam Choy's Island Flavors brings to the table his island tales and food with this delightful new volume. Filled with anecdotes and photographs of his visits and the food memories associated with each voyage, he travels as far south as New Zealand, taking in along the way such farreaching islands as Samoa, Tonga and Tahiti. Starting with a very full section covering the ingredients used throughout the book, Choy discusses the various culinary influences from the Chinese in Fiji and Samoa and the French in the Marquesas, to the Indian British impact throughout the regions. Whether it's the GingerScallion Fried Rice from Fiji, or the piquant sweetsour flavors of the Kau'u OrangeGinger Chicken from Hawaii, the recipes offer simple techniques and full fresh flavors. Cooks will recognize the many staple ingredients such as orange juice and coconut milk, which appear regularly throughout the book in such combinations as Baked Snapper with OrangeCoconut Sauce of the Marquesas, or Samoan Coconut Rice and Baked Banana Vanilla Custard from Tahiti. In bringing together the groups of recipes, Choy conveys a light yet satisfying cuisine that enchants the taste buds and expands one's knowledge of Polynesian cuisine.Copyright 2002 Cahners Business Information, Inc.\"),\n",
              " Document(metadata={'uid': 'B0001XIZMQ', 'title': 'Mahatma Saffron Yellow Rice 5oz bag'}, page_content='Mahatma Saffron Yellow Rice has been the bestselling yellow rice in the U.S. since its introduction some 40 years ago. Saffron is the most precious and expensive spice in the world. Saffron dates back to the ancient Greeks. Saffron filaments are the dried stigma of the saffron flower. Each stigma contains only three filaments, which must be picked by hand. More than 75,000 flowers are used to make one pound of saffron spice. Saffron adds a unique flavor and exquisite color to the rice. Flavored with onion and garlic, either as a side dish, or as the beginning of your own Paella, Mahatma Saffron Yellow Rice makes every meal a special occasion.'),\n",
              " Document(metadata={'uid': 'B005Y3JQV2', 'title': 'Macadamia Shortbread Cookies'}, page_content='Kauai Kookies Macadamia Nut Shortbread'),\n",
              " Document(metadata={'uid': 'B0006G9BIA', 'title': 'Komodo Krupuk Udang'}, page_content='Krupuk Udang or Shrimp Crackers are the essential for Indonesian cooking or just snack time. Uncook shrimp crackers. Net wt 500G')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geração de Respostas\n",
        "- Configure o modelo treinado para receber perguntas dos usuários.\n",
        "Quando uma pergunta for recebida, utilize a integração RAG para recuperar informações relevantes do dataset AmazonTitles-1.3MM."
      ],
      "metadata": {
        "id": "MgvGh6SEnoQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"What features make wireless headphones ideal for sports?\"\n",
        "response = generate_response(\n",
        "    user_question\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmfLCfoELVCX",
        "outputId": "26db9ae5-c678-413d-a877-0fc8efa4e233"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Answer:**\n",
            "Your smartphone or tablet will receive voice commands from your favorite song player using this device. You'll also receive text messages via Skype while playingamesuch as Guitar Hero 2, Game Boy Advance ClassicD Player game play, Rock Band 4Droid VHS video streamerPlayStation Portable MP3R Video Streaming HDTVMVTT, and other popular entertainment platforms.This product may not work properly due back issues caused by software update whichas been disableduring installation.Please notethat any errors areported when installing our products through our website'support page\n",
            "\n",
            "**Sources:**\n",
            "- UID: B00DQB0JVK, Title: Puma Social Earbud Wmic Pink\n",
            "- UID: B00B4DFNJU, Title: Califone 2800 Listening First Headphone 3 Packs Blue, Yellow, Red\n",
            "- UID: B004QOA93E, Title: SONY DREX12IP InEar Stereo Headphones with Mic and Remote Black\n",
            "- UID: B009AWT01Y, Title: JBL Flip Wireless Bluetooth Speaker White\n",
            "- UID: B001SUZNGW, Title: Shark Motorcycle Audios Shkmbt88i Snowmobile Bluetooth Multi Interphone Headsets Intercom Set Black\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exclusão\n",
        "Antes de sair, não esqueça de deletar os arquivos criados executando a célula abaixo."
      ],
      "metadata": {
        "id": "bKF5hi1pbtZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if os.path.exists(FOLDER_PATH):\n",
        "    try:\n",
        "        shutil.rmtree(FOLDER_PATH)\n",
        "        print(f'Diretório \"{FOLDER_PATH}\" e todo o seu conteúdo foram excluídos com sucesso.')\n",
        "    except Exception as e:\n",
        "        print(f'Erro ao tentar excluir o diretório \"{FOLDER_PATH}\": {e}')\n",
        "else:\n",
        "    print(f'O diretório \"{FOLDER_PATH}\" não existe.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4_Lx9o_bUJs",
        "outputId": "f0ef22d3-502b-473e-b132-64862f20aa74"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório \"/content/drive/MyDrive/TheAmazonTitles\" e todo o seu conteúdo foram excluídos com sucesso.\n"
          ]
        }
      ]
    }
  ]
}